{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats\n",
    "import math \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as sm1\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_left</th>\n",
       "      <th>ct_score</th>\n",
       "      <th>t_score</th>\n",
       "      <th>map</th>\n",
       "      <th>bomb_planted</th>\n",
       "      <th>ct_health</th>\n",
       "      <th>t_health</th>\n",
       "      <th>ct_armor</th>\n",
       "      <th>t_armor</th>\n",
       "      <th>ct_money</th>\n",
       "      <th>...</th>\n",
       "      <th>t_grenade_flashbang</th>\n",
       "      <th>ct_grenade_smokegrenade</th>\n",
       "      <th>t_grenade_smokegrenade</th>\n",
       "      <th>ct_grenade_incendiarygrenade</th>\n",
       "      <th>t_grenade_incendiarygrenade</th>\n",
       "      <th>ct_grenade_molotovgrenade</th>\n",
       "      <th>t_grenade_molotovgrenade</th>\n",
       "      <th>ct_grenade_decoygrenade</th>\n",
       "      <th>t_grenade_decoygrenade</th>\n",
       "      <th>round_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>...</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "      <td>122410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10782</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>501</td>\n",
       "      <td>502</td>\n",
       "      <td>415</td>\n",
       "      <td>477</td>\n",
       "      <td>1360</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>de_inferno</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11226</td>\n",
       "      <td>11683</td>\n",
       "      <td>12161</td>\n",
       "      <td>23811</td>\n",
       "      <td>108726</td>\n",
       "      <td>68258</td>\n",
       "      <td>63759</td>\n",
       "      <td>15886</td>\n",
       "      <td>17722</td>\n",
       "      <td>2434</td>\n",
       "      <td>...</td>\n",
       "      <td>41241</td>\n",
       "      <td>51955</td>\n",
       "      <td>53579</td>\n",
       "      <td>69051</td>\n",
       "      <td>120058</td>\n",
       "      <td>116893</td>\n",
       "      <td>59004</td>\n",
       "      <td>119128</td>\n",
       "      <td>119372</td>\n",
       "      <td>62406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_left ct_score t_score         map bomb_planted ct_health t_health  \\\n",
       "count     122410   122410  122410      122410       122410    122410   122410   \n",
       "unique     10782       33      34           8            2       501      502   \n",
       "top        175.0      0.0     0.0  de_inferno        False     500.0    500.0   \n",
       "freq       11226    11683   12161       23811       108726     68258    63759   \n",
       "\n",
       "       ct_armor t_armor ct_money  ... t_grenade_flashbang  \\\n",
       "count    122410  122410   122410  ...              122410   \n",
       "unique      415     477     1360  ...                   7   \n",
       "top       500.0     0.0   4000.0  ...                 0.0   \n",
       "freq      15886   17722     2434  ...               41241   \n",
       "\n",
       "       ct_grenade_smokegrenade t_grenade_smokegrenade  \\\n",
       "count                   122410                 122410   \n",
       "unique                       7                      7   \n",
       "top                        0.0                    0.0   \n",
       "freq                     51955                  53579   \n",
       "\n",
       "       ct_grenade_incendiarygrenade t_grenade_incendiarygrenade  \\\n",
       "count                        122410                      122410   \n",
       "unique                            6                           4   \n",
       "top                             0.0                         0.0   \n",
       "freq                          69051                      120058   \n",
       "\n",
       "       ct_grenade_molotovgrenade t_grenade_molotovgrenade  \\\n",
       "count                     122410                   122410   \n",
       "unique                         4                        6   \n",
       "top                          0.0                      0.0   \n",
       "freq                      116893                    59004   \n",
       "\n",
       "       ct_grenade_decoygrenade t_grenade_decoygrenade round_winner  \n",
       "count                   122410                 122410       122410  \n",
       "unique                       4                      3            2  \n",
       "top                        0.0                    0.0            T  \n",
       "freq                    119128                 119372        62406  \n",
       "\n",
       "[4 rows x 97 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualitzarem només 3 decimals per mostra\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Funcio per a llegir dades en format csv\n",
    "def load_dataset(path):\n",
    "    dataset = pd.read_csv(path, header=0, delimiter=',',decimal=',')\n",
    "    return dataset\n",
    "\n",
    "# Carreguem dataset d'exemple\n",
    "dataset = load_dataset('csgo_round_snapshots.csv')\n",
    "data = dataset.values\n",
    "dataset.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('csgo_round_snapshots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no tenim null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a les dades hi ha 3 columnes formades per string, com ens indiquen tipus de dades, podem fer servir ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct_weapon_bizon\n",
      "ct_weapon_g3sg1\n",
      "t_weapon_m249\n",
      "ct_weapon_negev\n",
      "ct_weapon_r8revolver\n",
      "ct_weapon_sawedoff\n"
     ]
    }
   ],
   "source": [
    "t=[]\n",
    "for i in dataset.columns:\n",
    "    t.append(dataset[i].nunique())\n",
    "temp =[]\n",
    "for i in range(len(t)):\n",
    "    if t[i]==1:\n",
    "        temp.append(i)\n",
    "        print(dataset.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91,)\n"
     ]
    }
   ],
   "source": [
    "for i in temp[::-1]:\n",
    "    dataset=dataset.drop([dataset.columns[i]],axis=1)\n",
    "print(dataset.columns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_left</th>\n",
       "      <th>ct_score</th>\n",
       "      <th>t_score</th>\n",
       "      <th>map</th>\n",
       "      <th>bomb_planted</th>\n",
       "      <th>ct_health</th>\n",
       "      <th>t_health</th>\n",
       "      <th>ct_armor</th>\n",
       "      <th>t_armor</th>\n",
       "      <th>ct_money</th>\n",
       "      <th>...</th>\n",
       "      <th>t_grenade_flashbang</th>\n",
       "      <th>ct_grenade_smokegrenade</th>\n",
       "      <th>t_grenade_smokegrenade</th>\n",
       "      <th>ct_grenade_incendiarygrenade</th>\n",
       "      <th>t_grenade_incendiarygrenade</th>\n",
       "      <th>ct_grenade_molotovgrenade</th>\n",
       "      <th>t_grenade_molotovgrenade</th>\n",
       "      <th>ct_grenade_decoygrenade</th>\n",
       "      <th>t_grenade_decoygrenade</th>\n",
       "      <th>round_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>de_dust2</td>\n",
       "      <td>False</td>\n",
       "      <td>500.000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>de_dust2</td>\n",
       "      <td>False</td>\n",
       "      <td>500.000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>300.000</td>\n",
       "      <td>600.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>de_dust2</td>\n",
       "      <td>False</td>\n",
       "      <td>391.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>294.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>de_dust2</td>\n",
       "      <td>False</td>\n",
       "      <td>391.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>294.000</td>\n",
       "      <td>200.000</td>\n",
       "      <td>750.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174.970</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>de_dust2</td>\n",
       "      <td>False</td>\n",
       "      <td>500.000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>192.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18350.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_left  ct_score  t_score       map  bomb_planted  ct_health  t_health  \\\n",
       "0    175.000     0.000    0.000  de_dust2         False    500.000   500.000   \n",
       "1    156.030     0.000    0.000  de_dust2         False    500.000   500.000   \n",
       "2     96.030     0.000    0.000  de_dust2         False    391.000   400.000   \n",
       "3     76.030     0.000    0.000  de_dust2         False    391.000   400.000   \n",
       "4    174.970     1.000    0.000  de_dust2         False    500.000   500.000   \n",
       "\n",
       "   ct_armor  t_armor  ct_money  ...  t_grenade_flashbang  \\\n",
       "0     0.000    0.000  4000.000  ...                0.000   \n",
       "1   400.000  300.000   600.000  ...                0.000   \n",
       "2   294.000  200.000   750.000  ...                0.000   \n",
       "3   294.000  200.000   750.000  ...                0.000   \n",
       "4   192.000    0.000 18350.000  ...                0.000   \n",
       "\n",
       "   ct_grenade_smokegrenade  t_grenade_smokegrenade  \\\n",
       "0                    0.000                   0.000   \n",
       "1                    0.000                   2.000   \n",
       "2                    0.000                   2.000   \n",
       "3                    0.000                   0.000   \n",
       "4                    0.000                   0.000   \n",
       "\n",
       "   ct_grenade_incendiarygrenade  t_grenade_incendiarygrenade  \\\n",
       "0                         0.000                        0.000   \n",
       "1                         0.000                        0.000   \n",
       "2                         0.000                        0.000   \n",
       "3                         0.000                        0.000   \n",
       "4                         0.000                        0.000   \n",
       "\n",
       "   ct_grenade_molotovgrenade  t_grenade_molotovgrenade  \\\n",
       "0                      0.000                     0.000   \n",
       "1                      0.000                     0.000   \n",
       "2                      0.000                     0.000   \n",
       "3                      0.000                     0.000   \n",
       "4                      0.000                     0.000   \n",
       "\n",
       "   ct_grenade_decoygrenade  t_grenade_decoygrenade  round_winner  \n",
       "0                    0.000                   0.000            CT  \n",
       "1                    0.000                   0.000            CT  \n",
       "2                    0.000                   0.000            CT  \n",
       "3                    0.000                   0.000            CT  \n",
       "4                    0.000                   0.000            CT  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.shape\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertir strings en ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "label_encoder = sklearn.preprocessing.LabelEncoder() \n",
    "dataset['map'] = label_encoder.fit_transform(dataset['map'])\n",
    "dataset['bomb_planted'] = label_encoder.fit_transform(dataset['bomb_planted'])\n",
    "dataset['round_winner'] = label_encoder.fit_transform(dataset['round_winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afegir variable de diferencia entre jugadors vius\n",
    "dataset['difference_between_players_alive']=dataset['t_players_alive']-dataset['ct_players_alive']\n",
    "dataset['difference_between_players_health']=dataset['t_health']-dataset['ct_health']\n",
    "dataset['difference_between_players_armor']=dataset['t_armor']-dataset['ct_armor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['difference_between_players_alive']\n",
    "#dataset=(dataset-dataset.mean())/dataset.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = dataset.reset_index()\n",
    "y = dataset.filter(['round_winner'])\n",
    "X =dataset.drop(['round_winner'],axis=1)\n",
    "X=(X-X.mean())/X.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.2,random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oriol\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 selected features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\"), max_features=10)\n",
    "embeded_lr_selector.fit(X, y.values.ravel())\n",
    "\n",
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bomb_planted',\n",
       " 't_helmets',\n",
       " 't_weapon_ak47',\n",
       " 'ct_weapon_awp',\n",
       " 'ct_weapon_m4a4',\n",
       " 't_weapon_sg553',\n",
       " 't_grenade_smokegrenade',\n",
       " 'difference_between_players_alive',\n",
       " 'difference_between_players_health',\n",
       " 'difference_between_players_armor']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_lr_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 93\n",
      "selected features: 92\n",
      "features with coefficients shrank to zero: 1\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.2,random_state =42)\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "sel_.fit(X_train, np.ravel(Y_train,order='C'))\n",
    "sel_.get_support()\n",
    "X_train = pd.DataFrame(X_train)\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97928, 92), (24482, 92))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats\n",
    "X_train = sel_.transform(X_train)\n",
    "X_test = sel_.transform(X_test)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 92\n",
      "selected features: 30\n",
      "Int64Index([ 4,  5,  7,  8,  9, 10, 12, 15, 16, 17, 18, 20, 21, 27, 31, 34, 36,\n",
      "            39, 46, 57, 58, 59, 69, 80, 82, 83, 86, 89, 90, 91],\n",
      "           dtype='int64')\n",
      "features with coefficients shrank to zero: 0\n"
     ]
    }
   ],
   "source": [
    "#X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.2,random_state =42)\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2', solver='liblinear'))\n",
    "sel_.fit(X_train, np.ravel(Y_train,order='C'))\n",
    "sel_.get_support()\n",
    "X_train = pd.DataFrame(X_train)\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print(selected_feat)\n",
    "print('features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((97928, 30), (97928, 30))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "print(removed_feats)\n",
    "X_train_selected = sel_.transform(X_train)\n",
    "X_test_selected = sel_.transform(X_test)\n",
    "X_train_selected.shape, X_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8563434359937914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "# Train the classifier\n",
    "clf.fit(X_train_selected,np.ravel(Y_train,order='C'))\n",
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred = clf.predict(X_test_selected)\n",
    "# View The Accuracy Of Our Selected Feature Model\n",
    "print(\"Accuracy\",accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oriol\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85     12004\n",
      "           1       0.88      0.81      0.84     12478\n",
      "\n",
      "    accuracy                           0.85     24482\n",
      "   macro avg       0.85      0.85      0.85     24482\n",
      "weighted avg       0.85      0.85      0.85     24482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.2,random_state =42)\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(X_train,Y_train.values.ravel())\n",
    "pred_3 = model_3.predict(X_test)\n",
    "cr3 = classification_report(Y_test.values.ravel(),pred_3)\n",
    "print(cr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba de Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CUDA: False\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100        # number of samples during training\n",
    "test_batch_size = 1000  # number of samples for test \n",
    "epochs = 5              # number of epochs to train (default: 14)\n",
    "lr = 0.01               # learning rate (default: 1.0)\n",
    "gamma = 0.7             # Learning rate step gamma (default: 0.7)\n",
    "\n",
    "no_cuda = True          # disables CUDA training\n",
    "dry_run = False         # quickly check a single pass\n",
    "seed = 1                # random seed (default: 1)\n",
    "log_interval = 50       # how many batches to wait before logging training status\n",
    "save_model = False     # For Saving the current Model\n",
    "\n",
    "\n",
    "# Check if cuda is available\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "print(f\"USING CUDA: {use_cuda}\")\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# define the device where to compute (cpu or gpu)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': batch_size}\n",
    "test_kwargs = {'batch_size': test_batch_size}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.w = torch.nn.Linear(30, 1)      # creem un model amb 784 entrades i 1 sortida\n",
    "\n",
    "    def forward(self, x):                    # x:  bsx28x28\n",
    "        x = torch.flatten(x, 1)              # flatten converteix una matriu en un array  x-> 28x28 -> 784x1\n",
    "        x = self.w(x)                        # aplica els pesos sum(w*x) ->  784x1 -> 1\n",
    "        x = torch.sigmoid(x)            # aplica la sigmoid  <- SVM la fa servir??\n",
    "        return torch.flatten(x, 0)      # return bs probs\n",
    "class LogisticLoss(torch.nn.modules.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticLoss, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        batch_size = outputs.size()[0]\n",
    "        outputs = (outputs * 2) - 1\n",
    "        labels = (labels * 2) - 1  # labels -> 1 or -1\n",
    "        return torch.sum(torch.log(1 + torch.exp(-(outputs.t() * labels)))) / batch_size\n",
    "\n",
    "class HingeLoss(torch.nn.modules.Module):\n",
    "    def __init__(self):\n",
    "        super(HingeLoss, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        batch_size = outputs.size()[0]\n",
    "        outputs = (outputs * 2) - 1\n",
    "        labels = (labels * 2) - 1   # labels -> 1 or -1\n",
    "        return torch.sum(torch.clamp(1 - outputs.t() * labels, min=0)) / batch_size # modificar el 1 per la loss corresponent\n",
    "def visualize_model(model):\n",
    "    # Apartat B. Mostrar pesos del model\n",
    "    plt.figure(0)\n",
    "    #extraiem els pesos del model i els reformatajem en format imatge.\n",
    "    plt.imshow(model.w.weight.detach().numpy().reshape(28, 28), interpolation='nearest', cmap=plt.cm.RdBu)\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_confusion_matrix(y_pred, y_real):\n",
    "    #mostra la matriu de confusió\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "    plt.subplots(figsize=(10, 6))\n",
    "    sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch, log_interval):\n",
    "    #Ens posem en mode entrenament.\n",
    "    model.train()\n",
    "    #iterem les dades en batches (o lots)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # en el cas de treballar en cuda o gpu, ara els hi posariem\n",
    "        optimizer.zero_grad()  # posem el gradient a zero (important) ja que sino, s'aniria acumulant a cada iteració\n",
    "        output = model(data)   # fem un predict del model amb les dades actuals\n",
    "        loss = criterion(output.view_as(target), target.type_as(output))  # calculem el error obtingut\n",
    "        loss.backward()             # li diem que calculi el gradient\n",
    "        optimizer.step()            # actualitza els pesos amb el gradient calculat\n",
    "        if batch_idx % log_interval == 0:  # cada log_interval loops mostrem informació\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "            #visualize_model(model)\n",
    "def test(model, device, test_loader, criterion, show_confusion_matrix=False):\n",
    "    model.eval()     # ens posem en mode evaluació\n",
    "    test_loss = 0    # variables per acumular resultats\n",
    "    correct = 0\n",
    "    all_preds = [] \n",
    "    all_outputs = [] \n",
    "    all_targets = []\n",
    "    with torch.no_grad():  # li estem dient que estem en evaluacio, i que necesitem calcular el gradient aqui dins \n",
    "        for data, target in test_loader:   # per cada batch de test\n",
    "            data, target = data.to(device), target.to(device)  # posar-ho a la cpu o a la gpu\n",
    "            output = model(data)    # fer la prediccio\n",
    "            test_loss += criterion(output.view_as(target), target.type_as(output)).item() * data.shape[0]  # acumulem error\n",
    "            pred = (output > 0.5) * 1  # per comprobar la prediccio escollim el threshold a 0.5\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            all_preds.extend(pred)\n",
    "            all_targets.extend(target)\n",
    "            all_outputs.extend(output)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset) # fem la mitja de l'error del dataset\n",
    "    if show_confusion_matrix:\n",
    "        visualize_confusion_matrix(all_targets, all_preds)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return all_outputs\n",
    "# Definim un pipeline que se li aplicarà a les dades del dataset\n",
    "\n",
    "\n",
    "# Aqui agafem les dades del propi torch. Si no les tenim, amb el parametre download ens el baixarem automaticament.\n",
    "# Esculliu on voleu descarregar-vos les dades i intenteu de no anar-les replicant per totes les carpetes..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNING RATE USED: [1]\n",
      "Train Epoch: 1 [0/97928 (0%)]\tLoss: 69.680779\n",
      "Train Epoch: 1 [5000/97928 (5%)]\tLoss: 73.889954\n",
      "Train Epoch: 1 [10000/97928 (10%)]\tLoss: 75.205460\n",
      "Train Epoch: 1 [15000/97928 (15%)]\tLoss: 76.242340\n",
      "Train Epoch: 1 [20000/97928 (20%)]\tLoss: 76.370201\n",
      "Train Epoch: 1 [25000/97928 (26%)]\tLoss: 78.207947\n",
      "Train Epoch: 1 [30000/97928 (31%)]\tLoss: 79.742867\n",
      "Train Epoch: 1 [35000/97928 (36%)]\tLoss: 75.431351\n",
      "Train Epoch: 1 [40000/97928 (41%)]\tLoss: 79.833481\n",
      "Train Epoch: 1 [45000/97928 (46%)]\tLoss: 76.264008\n",
      "Train Epoch: 1 [50000/97928 (51%)]\tLoss: 78.730911\n",
      "Train Epoch: 1 [55000/97928 (56%)]\tLoss: 80.859467\n",
      "Train Epoch: 1 [60000/97928 (61%)]\tLoss: 79.244339\n",
      "Train Epoch: 1 [65000/97928 (66%)]\tLoss: 76.351234\n",
      "Train Epoch: 1 [70000/97928 (71%)]\tLoss: 77.368546\n",
      "Train Epoch: 1 [75000/97928 (77%)]\tLoss: 76.847626\n",
      "Train Epoch: 1 [80000/97928 (82%)]\tLoss: 76.309860\n",
      "Train Epoch: 1 [85000/97928 (87%)]\tLoss: 77.349098\n",
      "Train Epoch: 1 [90000/97928 (92%)]\tLoss: 78.822533\n",
      "Train Epoch: 1 [95000/97928 (97%)]\tLoss: 79.663231\n",
      "\n",
      "Test set: Average loss: 746.4646, Accuracy: 8895/24482 (36.33%)\n",
      "\n",
      "LEARNING RATE USED: [0.7]\n",
      "Train Epoch: 2 [0/97928 (0%)]\tLoss: 77.330109\n",
      "Train Epoch: 2 [5000/97928 (5%)]\tLoss: 75.940842\n",
      "Train Epoch: 2 [10000/97928 (10%)]\tLoss: 73.977463\n",
      "Train Epoch: 2 [15000/97928 (15%)]\tLoss: 74.512466\n",
      "Train Epoch: 2 [20000/97928 (20%)]\tLoss: 77.789856\n",
      "Train Epoch: 2 [25000/97928 (26%)]\tLoss: 76.933762\n",
      "Train Epoch: 2 [30000/97928 (31%)]\tLoss: 75.261810\n",
      "Train Epoch: 2 [35000/97928 (36%)]\tLoss: 76.430389\n",
      "Train Epoch: 2 [40000/97928 (41%)]\tLoss: 78.026489\n",
      "Train Epoch: 2 [45000/97928 (46%)]\tLoss: 77.930710\n",
      "Train Epoch: 2 [50000/97928 (51%)]\tLoss: 78.788925\n",
      "Train Epoch: 2 [55000/97928 (56%)]\tLoss: 75.873718\n",
      "Train Epoch: 2 [60000/97928 (61%)]\tLoss: 74.059662\n",
      "Train Epoch: 2 [65000/97928 (66%)]\tLoss: 78.733994\n",
      "Train Epoch: 2 [70000/97928 (71%)]\tLoss: 77.403267\n",
      "Train Epoch: 2 [75000/97928 (77%)]\tLoss: 79.706749\n",
      "Train Epoch: 2 [80000/97928 (82%)]\tLoss: 76.188087\n",
      "Train Epoch: 2 [85000/97928 (87%)]\tLoss: 79.316826\n",
      "Train Epoch: 2 [90000/97928 (92%)]\tLoss: 74.412674\n",
      "Train Epoch: 2 [95000/97928 (97%)]\tLoss: 77.624023\n",
      "\n",
      "Test set: Average loss: 727.9212, Accuracy: 10594/24482 (43.27%)\n",
      "\n",
      "LEARNING RATE USED: [0.48999999999999994]\n",
      "Train Epoch: 3 [0/97928 (0%)]\tLoss: 75.166962\n",
      "Train Epoch: 3 [5000/97928 (5%)]\tLoss: 75.464226\n",
      "Train Epoch: 3 [10000/97928 (10%)]\tLoss: 76.433098\n",
      "Train Epoch: 3 [15000/97928 (15%)]\tLoss: 74.086693\n",
      "Train Epoch: 3 [20000/97928 (20%)]\tLoss: 70.948303\n",
      "Train Epoch: 3 [25000/97928 (26%)]\tLoss: 76.852737\n",
      "Train Epoch: 3 [30000/97928 (31%)]\tLoss: 76.244400\n",
      "Train Epoch: 3 [35000/97928 (36%)]\tLoss: 76.525070\n",
      "Train Epoch: 3 [40000/97928 (41%)]\tLoss: 77.770607\n",
      "Train Epoch: 3 [45000/97928 (46%)]\tLoss: 75.310402\n",
      "Train Epoch: 3 [50000/97928 (51%)]\tLoss: 76.148598\n",
      "Train Epoch: 3 [55000/97928 (56%)]\tLoss: 78.507507\n",
      "Train Epoch: 3 [60000/97928 (61%)]\tLoss: 73.686501\n",
      "Train Epoch: 3 [65000/97928 (66%)]\tLoss: 78.398285\n",
      "Train Epoch: 3 [70000/97928 (71%)]\tLoss: 75.665741\n",
      "Train Epoch: 3 [75000/97928 (77%)]\tLoss: 79.134811\n",
      "Train Epoch: 3 [80000/97928 (82%)]\tLoss: 73.151039\n",
      "Train Epoch: 3 [85000/97928 (87%)]\tLoss: 76.596268\n",
      "Train Epoch: 3 [90000/97928 (92%)]\tLoss: 77.247520\n",
      "Train Epoch: 3 [95000/97928 (97%)]\tLoss: 72.861359\n",
      "\n",
      "Test set: Average loss: 743.1169, Accuracy: 12014/24482 (49.07%)\n",
      "\n",
      "LEARNING RATE USED: [0.3429999999999999]\n",
      "Train Epoch: 4 [0/97928 (0%)]\tLoss: 76.118881\n",
      "Train Epoch: 4 [5000/97928 (5%)]\tLoss: 72.455841\n",
      "Train Epoch: 4 [10000/97928 (10%)]\tLoss: 71.090477\n",
      "Train Epoch: 4 [15000/97928 (15%)]\tLoss: 74.823875\n",
      "Train Epoch: 4 [20000/97928 (20%)]\tLoss: 77.018387\n",
      "Train Epoch: 4 [25000/97928 (26%)]\tLoss: 74.121307\n",
      "Train Epoch: 4 [30000/97928 (31%)]\tLoss: 73.895546\n",
      "Train Epoch: 4 [35000/97928 (36%)]\tLoss: 76.177025\n",
      "Train Epoch: 4 [40000/97928 (41%)]\tLoss: 78.489281\n",
      "Train Epoch: 4 [45000/97928 (46%)]\tLoss: 77.121819\n",
      "Train Epoch: 4 [50000/97928 (51%)]\tLoss: 73.045303\n",
      "Train Epoch: 4 [55000/97928 (56%)]\tLoss: 74.464912\n",
      "Train Epoch: 4 [60000/97928 (61%)]\tLoss: 71.651688\n",
      "Train Epoch: 4 [65000/97928 (66%)]\tLoss: 75.912834\n",
      "Train Epoch: 4 [70000/97928 (71%)]\tLoss: 70.832123\n",
      "Train Epoch: 4 [75000/97928 (77%)]\tLoss: 74.307602\n",
      "Train Epoch: 4 [80000/97928 (82%)]\tLoss: 75.867783\n",
      "Train Epoch: 4 [85000/97928 (87%)]\tLoss: 75.625648\n",
      "Train Epoch: 4 [90000/97928 (92%)]\tLoss: 72.982887\n",
      "Train Epoch: 4 [95000/97928 (97%)]\tLoss: 75.805710\n",
      "\n",
      "Test set: Average loss: 760.3699, Accuracy: 8363/24482 (34.16%)\n",
      "\n",
      "LEARNING RATE USED: [0.24009999999999992]\n",
      "Train Epoch: 5 [0/97928 (0%)]\tLoss: 77.545891\n",
      "Train Epoch: 5 [5000/97928 (5%)]\tLoss: 71.153397\n",
      "Train Epoch: 5 [10000/97928 (10%)]\tLoss: 75.131302\n",
      "Train Epoch: 5 [15000/97928 (15%)]\tLoss: 73.978996\n",
      "Train Epoch: 5 [20000/97928 (20%)]\tLoss: 69.632912\n",
      "Train Epoch: 5 [25000/97928 (26%)]\tLoss: 73.776917\n",
      "Train Epoch: 5 [30000/97928 (31%)]\tLoss: 76.828644\n",
      "Train Epoch: 5 [35000/97928 (36%)]\tLoss: 72.588737\n",
      "Train Epoch: 5 [40000/97928 (41%)]\tLoss: 74.655975\n",
      "Train Epoch: 5 [45000/97928 (46%)]\tLoss: 77.594902\n",
      "Train Epoch: 5 [50000/97928 (51%)]\tLoss: 75.087288\n",
      "Train Epoch: 5 [55000/97928 (56%)]\tLoss: 74.911751\n",
      "Train Epoch: 5 [60000/97928 (61%)]\tLoss: 75.178757\n",
      "Train Epoch: 5 [65000/97928 (66%)]\tLoss: 71.983162\n",
      "Train Epoch: 5 [70000/97928 (71%)]\tLoss: 72.583031\n",
      "Train Epoch: 5 [75000/97928 (77%)]\tLoss: 76.775482\n",
      "Train Epoch: 5 [80000/97928 (82%)]\tLoss: 70.681976\n",
      "Train Epoch: 5 [85000/97928 (87%)]\tLoss: 74.059502\n",
      "Train Epoch: 5 [90000/97928 (92%)]\tLoss: 74.220428\n",
      "Train Epoch: 5 [95000/97928 (97%)]\tLoss: 75.817604\n",
      "\n",
      "Test set: Average loss: 700.2729, Accuracy: 12315/24482 (50.30%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "target = pd.DataFrame(Y_train[\"round_winner\"])\n",
    "data_train = data_utils.TensorDataset(torch.Tensor(np.array(X_train_selected)), torch.Tensor(np.array(target)))\n",
    "train_loader = data_utils.DataLoader(data_train, **train_kwargs)\n",
    "\n",
    "target = pd.DataFrame(Y_test[\"round_winner\"])\n",
    "data_test = data_utils.TensorDataset(torch.Tensor(np.array(X_test_selected)), torch.Tensor(np.array(target)))\n",
    "test_loader = data_utils.DataLoader(data_test, **test_kwargs)\n",
    "\n",
    "model = Model().to(device)  # instanciació del model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1,weight_decay=0.1)   # optimitzador (Apartat C. Aqui podem definir el weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)  # permet reduir el Learning rate\n",
    "\n",
    "criterion = LogisticLoss()\n",
    "#criterion = HingeLoss()\n",
    "#criterion = torch.nn.BCELoss(reduction='mean')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # A cada epoca, fem un entrenament del model (es veu un cop cada exemple)\n",
    "    print(\"LEARNING RATE USED: {}\".format(scheduler.get_last_lr()))\n",
    "    train(model, device, train_loader, optimizer, criterion, epoch, log_interval)\n",
    "    test(model, device, test_loader, criterion,show_confusion_matrix=False)\n",
    "    scheduler.step()  # reduim el Learning Rate segons el scheduler StepLR que fa servir gamma\n",
    "\n",
    "if save_model:\n",
    "    torch.save(model.state_dict(), \"mnist.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNING RATE USED: [0.16806999999999994]\n",
      "Train Epoch: 1 [0/97928 (0%)]\tLoss: 100.713356\n",
      "Train Epoch: 1 [5000/97928 (5%)]\tLoss: 99.720139\n",
      "Train Epoch: 1 [10000/97928 (10%)]\tLoss: 92.265038\n",
      "Train Epoch: 1 [15000/97928 (15%)]\tLoss: 101.535110\n",
      "Train Epoch: 1 [20000/97928 (20%)]\tLoss: 86.389015\n",
      "Train Epoch: 1 [25000/97928 (26%)]\tLoss: 103.763710\n",
      "Train Epoch: 1 [30000/97928 (31%)]\tLoss: 114.221512\n",
      "Train Epoch: 1 [35000/97928 (36%)]\tLoss: 98.968407\n",
      "Train Epoch: 1 [40000/97928 (41%)]\tLoss: 93.044739\n",
      "Train Epoch: 1 [45000/97928 (46%)]\tLoss: 105.309433\n",
      "Train Epoch: 1 [50000/97928 (51%)]\tLoss: 100.000000\n",
      "Train Epoch: 1 [55000/97928 (56%)]\tLoss: 99.521965\n",
      "Train Epoch: 1 [60000/97928 (61%)]\tLoss: 92.650604\n",
      "Train Epoch: 1 [65000/97928 (66%)]\tLoss: 100.000000\n",
      "Train Epoch: 1 [70000/97928 (71%)]\tLoss: 93.573494\n",
      "Train Epoch: 1 [75000/97928 (77%)]\tLoss: 97.709206\n",
      "Train Epoch: 1 [80000/97928 (82%)]\tLoss: 98.165573\n",
      "Train Epoch: 1 [85000/97928 (87%)]\tLoss: 101.804543\n",
      "Train Epoch: 1 [90000/97928 (92%)]\tLoss: 88.043610\n",
      "Train Epoch: 1 [95000/97928 (97%)]\tLoss: 80.600487\n",
      "\n",
      "Test set: Average loss: 971.9694, Accuracy: 12478/24482 (50.97%)\n",
      "\n",
      "LEARNING RATE USED: [0.11764899999999995]\n",
      "Train Epoch: 2 [0/97928 (0%)]\tLoss: 107.102356\n",
      "Train Epoch: 2 [5000/97928 (5%)]\tLoss: 98.137863\n",
      "Train Epoch: 2 [10000/97928 (10%)]\tLoss: 92.216400\n",
      "Train Epoch: 2 [15000/97928 (15%)]\tLoss: 101.528099\n",
      "Train Epoch: 2 [20000/97928 (20%)]\tLoss: 86.844772\n",
      "Train Epoch: 2 [25000/97928 (26%)]\tLoss: 103.698898\n",
      "Train Epoch: 2 [30000/97928 (31%)]\tLoss: 114.301346\n",
      "Train Epoch: 2 [35000/97928 (36%)]\tLoss: 98.577957\n",
      "Train Epoch: 2 [40000/97928 (41%)]\tLoss: 92.987335\n",
      "Train Epoch: 2 [45000/97928 (46%)]\tLoss: 105.301483\n",
      "Train Epoch: 2 [50000/97928 (51%)]\tLoss: 100.000000\n",
      "Train Epoch: 2 [55000/97928 (56%)]\tLoss: 96.187256\n",
      "Train Epoch: 2 [60000/97928 (61%)]\tLoss: 92.728867\n",
      "Train Epoch: 2 [65000/97928 (66%)]\tLoss: 100.000000\n",
      "Train Epoch: 2 [70000/97928 (71%)]\tLoss: 93.083458\n",
      "Train Epoch: 2 [75000/97928 (77%)]\tLoss: 97.146614\n",
      "Train Epoch: 2 [80000/97928 (82%)]\tLoss: 98.221863\n",
      "Train Epoch: 2 [85000/97928 (87%)]\tLoss: 101.759033\n",
      "Train Epoch: 2 [90000/97928 (92%)]\tLoss: 88.166183\n",
      "Train Epoch: 2 [95000/97928 (97%)]\tLoss: 80.285057\n",
      "\n",
      "Test set: Average loss: 971.9313, Accuracy: 12478/24482 (50.97%)\n",
      "\n",
      "LEARNING RATE USED: [0.08235429999999996]\n",
      "Train Epoch: 3 [0/97928 (0%)]\tLoss: 107.135399\n",
      "Train Epoch: 3 [5000/97928 (5%)]\tLoss: 96.492088\n",
      "Train Epoch: 3 [10000/97928 (10%)]\tLoss: 92.065193\n",
      "Train Epoch: 3 [15000/97928 (15%)]\tLoss: 101.571930\n",
      "Train Epoch: 3 [20000/97928 (20%)]\tLoss: 83.042404\n",
      "Train Epoch: 3 [25000/97928 (26%)]\tLoss: 103.653030\n",
      "Train Epoch: 3 [30000/97928 (31%)]\tLoss: 114.318039\n",
      "Train Epoch: 3 [35000/97928 (36%)]\tLoss: 98.302689\n",
      "Train Epoch: 3 [40000/97928 (41%)]\tLoss: 92.834473\n",
      "Train Epoch: 3 [45000/97928 (46%)]\tLoss: 105.303116\n",
      "Train Epoch: 3 [50000/97928 (51%)]\tLoss: 100.000000\n",
      "Train Epoch: 3 [55000/97928 (56%)]\tLoss: 92.614349\n",
      "Train Epoch: 3 [60000/97928 (61%)]\tLoss: 92.791336\n",
      "Train Epoch: 3 [65000/97928 (66%)]\tLoss: 100.000000\n",
      "Train Epoch: 3 [70000/97928 (71%)]\tLoss: 93.074577\n",
      "Train Epoch: 3 [75000/97928 (77%)]\tLoss: 95.650734\n",
      "Train Epoch: 3 [80000/97928 (82%)]\tLoss: 98.276009\n",
      "Train Epoch: 3 [85000/97928 (87%)]\tLoss: 101.735931\n",
      "Train Epoch: 3 [90000/97928 (92%)]\tLoss: 88.067345\n",
      "Train Epoch: 3 [95000/97928 (97%)]\tLoss: 80.232010\n",
      "\n",
      "Test set: Average loss: 971.8854, Accuracy: 12478/24482 (50.97%)\n",
      "\n",
      "LEARNING RATE USED: [0.05764800999999997]\n",
      "Train Epoch: 4 [0/97928 (0%)]\tLoss: 107.168114\n",
      "Train Epoch: 4 [5000/97928 (5%)]\tLoss: 92.875710\n",
      "Train Epoch: 4 [10000/97928 (10%)]\tLoss: 91.851555\n",
      "Train Epoch: 4 [15000/97928 (15%)]\tLoss: 101.595032\n",
      "Train Epoch: 4 [20000/97928 (20%)]\tLoss: 83.328239\n",
      "Train Epoch: 4 [25000/97928 (26%)]\tLoss: 103.598747\n",
      "Train Epoch: 4 [30000/97928 (31%)]\tLoss: 114.282341\n",
      "Train Epoch: 4 [35000/97928 (36%)]\tLoss: 98.296967\n",
      "Train Epoch: 4 [40000/97928 (41%)]\tLoss: 92.897667\n",
      "Train Epoch: 4 [45000/97928 (46%)]\tLoss: 105.286285\n",
      "Train Epoch: 4 [50000/97928 (51%)]\tLoss: 100.000000\n",
      "Train Epoch: 4 [55000/97928 (56%)]\tLoss: 90.796432\n",
      "Train Epoch: 4 [60000/97928 (61%)]\tLoss: 92.846375\n",
      "Train Epoch: 4 [65000/97928 (66%)]\tLoss: 100.000008\n",
      "Train Epoch: 4 [70000/97928 (71%)]\tLoss: 93.043434\n",
      "Train Epoch: 4 [75000/97928 (77%)]\tLoss: 94.279900\n",
      "Train Epoch: 4 [80000/97928 (82%)]\tLoss: 98.311478\n",
      "Train Epoch: 4 [85000/97928 (87%)]\tLoss: 101.714561\n",
      "Train Epoch: 4 [90000/97928 (92%)]\tLoss: 88.049164\n",
      "Train Epoch: 4 [95000/97928 (97%)]\tLoss: 80.300911\n",
      "\n",
      "Test set: Average loss: 971.9039, Accuracy: 12478/24482 (50.97%)\n",
      "\n",
      "LEARNING RATE USED: [0.04035360699999998]\n",
      "Train Epoch: 5 [0/97928 (0%)]\tLoss: 107.166122\n",
      "Train Epoch: 5 [5000/97928 (5%)]\tLoss: 92.006622\n",
      "Train Epoch: 5 [10000/97928 (10%)]\tLoss: 91.746719\n",
      "Train Epoch: 5 [15000/97928 (15%)]\tLoss: 101.614944\n",
      "Train Epoch: 5 [20000/97928 (20%)]\tLoss: 83.422775\n",
      "Train Epoch: 5 [25000/97928 (26%)]\tLoss: 103.539452\n",
      "Train Epoch: 5 [30000/97928 (31%)]\tLoss: 114.186859\n",
      "Train Epoch: 5 [35000/97928 (36%)]\tLoss: 98.293503\n",
      "Train Epoch: 5 [40000/97928 (41%)]\tLoss: 92.963104\n",
      "Train Epoch: 5 [45000/97928 (46%)]\tLoss: 105.260475\n",
      "Train Epoch: 5 [50000/97928 (51%)]\tLoss: 100.000000\n",
      "Train Epoch: 5 [55000/97928 (56%)]\tLoss: 90.175598\n",
      "Train Epoch: 5 [60000/97928 (61%)]\tLoss: 92.894135\n",
      "Train Epoch: 5 [65000/97928 (66%)]\tLoss: 100.000000\n",
      "Train Epoch: 5 [70000/97928 (71%)]\tLoss: 93.024796\n",
      "Train Epoch: 5 [75000/97928 (77%)]\tLoss: 92.870224\n",
      "Train Epoch: 5 [80000/97928 (82%)]\tLoss: 98.319298\n",
      "Train Epoch: 5 [85000/97928 (87%)]\tLoss: 101.698967\n",
      "Train Epoch: 5 [90000/97928 (92%)]\tLoss: 88.088310\n",
      "Train Epoch: 5 [95000/97928 (97%)]\tLoss: 80.441223\n",
      "\n",
      "Test set: Average loss: 971.9845, Accuracy: 12478/24482 (50.97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#criterion = LogisticLoss()\n",
    "criterion = HingeLoss()\n",
    "#criterion = torch.nn.BCELoss(reduction='mean')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # A cada epoca, fem un entrenament del model (es veu un cop cada exemple)\n",
    "    print(\"LEARNING RATE USED: {}\".format(scheduler.get_last_lr()))\n",
    "    train(model, device, train_loader, optimizer, criterion, epoch, log_interval)\n",
    "    test(model, device, test_loader, criterion,show_confusion_matrix=False)\n",
    "    scheduler.step()  # reduim el Learning Rate segons el scheduler StepLR que fa servir gamma\n",
    "\n",
    "if save_model:\n",
    "    torch.save(model.state_dict(), \"mnist.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNING RATE USED: [0.028247524899999984]\n",
      "Train Epoch: 1 [0/97928 (0%)]\tLoss: 1.581788\n",
      "Train Epoch: 1 [5000/97928 (5%)]\tLoss: 0.729441\n",
      "Train Epoch: 1 [10000/97928 (10%)]\tLoss: 0.573056\n",
      "Train Epoch: 1 [15000/97928 (15%)]\tLoss: 0.641319\n",
      "Train Epoch: 1 [20000/97928 (20%)]\tLoss: 0.425861\n",
      "Train Epoch: 1 [25000/97928 (26%)]\tLoss: 0.508980\n",
      "Train Epoch: 1 [30000/97928 (31%)]\tLoss: 0.453294\n",
      "Train Epoch: 1 [35000/97928 (36%)]\tLoss: 0.421742\n",
      "Train Epoch: 1 [40000/97928 (41%)]\tLoss: 0.458444\n",
      "Train Epoch: 1 [45000/97928 (46%)]\tLoss: 0.495311\n",
      "Train Epoch: 1 [50000/97928 (51%)]\tLoss: 0.547342\n",
      "Train Epoch: 1 [55000/97928 (56%)]\tLoss: 0.441551\n",
      "Train Epoch: 1 [60000/97928 (61%)]\tLoss: 0.458410\n",
      "Train Epoch: 1 [65000/97928 (66%)]\tLoss: 0.512883\n",
      "Train Epoch: 1 [70000/97928 (71%)]\tLoss: 0.463834\n",
      "Train Epoch: 1 [75000/97928 (77%)]\tLoss: 0.497519\n",
      "Train Epoch: 1 [80000/97928 (82%)]\tLoss: 0.538224\n",
      "Train Epoch: 1 [85000/97928 (87%)]\tLoss: 0.541689\n",
      "Train Epoch: 1 [90000/97928 (92%)]\tLoss: 0.543323\n",
      "Train Epoch: 1 [95000/97928 (97%)]\tLoss: 0.435289\n",
      "\n",
      "Test set: Average loss: 0.4896, Accuracy: 18408/24482 (75.19%)\n",
      "\n",
      "LEARNING RATE USED: [0.019773267429999988]\n",
      "Train Epoch: 2 [0/97928 (0%)]\tLoss: 0.523672\n",
      "Train Epoch: 2 [5000/97928 (5%)]\tLoss: 0.452519\n",
      "Train Epoch: 2 [10000/97928 (10%)]\tLoss: 0.505495\n",
      "Train Epoch: 2 [15000/97928 (15%)]\tLoss: 0.566257\n",
      "Train Epoch: 2 [20000/97928 (20%)]\tLoss: 0.416742\n",
      "Train Epoch: 2 [25000/97928 (26%)]\tLoss: 0.496834\n",
      "Train Epoch: 2 [30000/97928 (31%)]\tLoss: 0.434098\n",
      "Train Epoch: 2 [35000/97928 (36%)]\tLoss: 0.413596\n",
      "Train Epoch: 2 [40000/97928 (41%)]\tLoss: 0.465997\n",
      "Train Epoch: 2 [45000/97928 (46%)]\tLoss: 0.494525\n",
      "Train Epoch: 2 [50000/97928 (51%)]\tLoss: 0.546157\n",
      "Train Epoch: 2 [55000/97928 (56%)]\tLoss: 0.441675\n",
      "Train Epoch: 2 [60000/97928 (61%)]\tLoss: 0.458820\n",
      "Train Epoch: 2 [65000/97928 (66%)]\tLoss: 0.511906\n",
      "Train Epoch: 2 [70000/97928 (71%)]\tLoss: 0.463581\n",
      "Train Epoch: 2 [75000/97928 (77%)]\tLoss: 0.497047\n",
      "Train Epoch: 2 [80000/97928 (82%)]\tLoss: 0.536447\n",
      "Train Epoch: 2 [85000/97928 (87%)]\tLoss: 0.541303\n",
      "Train Epoch: 2 [90000/97928 (92%)]\tLoss: 0.543100\n",
      "Train Epoch: 2 [95000/97928 (97%)]\tLoss: 0.435026\n",
      "\n",
      "Test set: Average loss: 0.4896, Accuracy: 18410/24482 (75.20%)\n",
      "\n",
      "LEARNING RATE USED: [0.01384128720099999]\n",
      "Train Epoch: 3 [0/97928 (0%)]\tLoss: 0.523671\n",
      "Train Epoch: 3 [5000/97928 (5%)]\tLoss: 0.451788\n",
      "Train Epoch: 3 [10000/97928 (10%)]\tLoss: 0.505246\n",
      "Train Epoch: 3 [15000/97928 (15%)]\tLoss: 0.564914\n",
      "Train Epoch: 3 [20000/97928 (20%)]\tLoss: 0.416247\n",
      "Train Epoch: 3 [25000/97928 (26%)]\tLoss: 0.496735\n",
      "Train Epoch: 3 [30000/97928 (31%)]\tLoss: 0.434253\n",
      "Train Epoch: 3 [35000/97928 (36%)]\tLoss: 0.413797\n",
      "Train Epoch: 3 [40000/97928 (41%)]\tLoss: 0.466157\n",
      "Train Epoch: 3 [45000/97928 (46%)]\tLoss: 0.494509\n",
      "Train Epoch: 3 [50000/97928 (51%)]\tLoss: 0.545980\n",
      "Train Epoch: 3 [55000/97928 (56%)]\tLoss: 0.441851\n",
      "Train Epoch: 3 [60000/97928 (61%)]\tLoss: 0.458621\n",
      "Train Epoch: 3 [65000/97928 (66%)]\tLoss: 0.511546\n",
      "Train Epoch: 3 [70000/97928 (71%)]\tLoss: 0.463865\n",
      "Train Epoch: 3 [75000/97928 (77%)]\tLoss: 0.496807\n",
      "Train Epoch: 3 [80000/97928 (82%)]\tLoss: 0.535154\n",
      "Train Epoch: 3 [85000/97928 (87%)]\tLoss: 0.541139\n",
      "Train Epoch: 3 [90000/97928 (92%)]\tLoss: 0.542990\n",
      "Train Epoch: 3 [95000/97928 (97%)]\tLoss: 0.434588\n",
      "\n",
      "Test set: Average loss: 0.4897, Accuracy: 18386/24482 (75.10%)\n",
      "\n",
      "LEARNING RATE USED: [0.009688901040699992]\n",
      "Train Epoch: 4 [0/97928 (0%)]\tLoss: 0.523632\n",
      "Train Epoch: 4 [5000/97928 (5%)]\tLoss: 0.451114\n",
      "Train Epoch: 4 [10000/97928 (10%)]\tLoss: 0.505108\n",
      "Train Epoch: 4 [15000/97928 (15%)]\tLoss: 0.563884\n",
      "Train Epoch: 4 [20000/97928 (20%)]\tLoss: 0.415821\n",
      "Train Epoch: 4 [25000/97928 (26%)]\tLoss: 0.496539\n",
      "Train Epoch: 4 [30000/97928 (31%)]\tLoss: 0.434329\n",
      "Train Epoch: 4 [35000/97928 (36%)]\tLoss: 0.413742\n",
      "Train Epoch: 4 [40000/97928 (41%)]\tLoss: 0.466067\n",
      "Train Epoch: 4 [45000/97928 (46%)]\tLoss: 0.494461\n",
      "Train Epoch: 4 [50000/97928 (51%)]\tLoss: 0.545801\n",
      "Train Epoch: 4 [55000/97928 (56%)]\tLoss: 0.442016\n",
      "Train Epoch: 4 [60000/97928 (61%)]\tLoss: 0.458471\n",
      "Train Epoch: 4 [65000/97928 (66%)]\tLoss: 0.511453\n",
      "Train Epoch: 4 [70000/97928 (71%)]\tLoss: 0.464319\n",
      "Train Epoch: 4 [75000/97928 (77%)]\tLoss: 0.496651\n",
      "Train Epoch: 4 [80000/97928 (82%)]\tLoss: 0.534116\n",
      "Train Epoch: 4 [85000/97928 (87%)]\tLoss: 0.541069\n",
      "Train Epoch: 4 [90000/97928 (92%)]\tLoss: 0.542938\n",
      "Train Epoch: 4 [95000/97928 (97%)]\tLoss: 0.434249\n",
      "\n",
      "Test set: Average loss: 0.4897, Accuracy: 18408/24482 (75.19%)\n",
      "\n",
      "LEARNING RATE USED: [0.006782230728489994]\n",
      "Train Epoch: 5 [0/97928 (0%)]\tLoss: 0.523573\n",
      "Train Epoch: 5 [5000/97928 (5%)]\tLoss: 0.450594\n",
      "Train Epoch: 5 [10000/97928 (10%)]\tLoss: 0.505049\n",
      "Train Epoch: 5 [15000/97928 (15%)]\tLoss: 0.563100\n",
      "Train Epoch: 5 [20000/97928 (20%)]\tLoss: 0.415494\n",
      "Train Epoch: 5 [25000/97928 (26%)]\tLoss: 0.496287\n",
      "Train Epoch: 5 [30000/97928 (31%)]\tLoss: 0.434297\n",
      "Train Epoch: 5 [35000/97928 (36%)]\tLoss: 0.413521\n",
      "Train Epoch: 5 [40000/97928 (41%)]\tLoss: 0.465800\n",
      "Train Epoch: 5 [45000/97928 (46%)]\tLoss: 0.494408\n",
      "Train Epoch: 5 [50000/97928 (51%)]\tLoss: 0.545610\n",
      "Train Epoch: 5 [55000/97928 (56%)]\tLoss: 0.442112\n",
      "Train Epoch: 5 [60000/97928 (61%)]\tLoss: 0.458357\n",
      "Train Epoch: 5 [65000/97928 (66%)]\tLoss: 0.511516\n",
      "Train Epoch: 5 [70000/97928 (71%)]\tLoss: 0.464800\n",
      "Train Epoch: 5 [75000/97928 (77%)]\tLoss: 0.496563\n",
      "Train Epoch: 5 [80000/97928 (82%)]\tLoss: 0.533418\n",
      "Train Epoch: 5 [85000/97928 (87%)]\tLoss: 0.541046\n",
      "Train Epoch: 5 [90000/97928 (92%)]\tLoss: 0.542915\n",
      "Train Epoch: 5 [95000/97928 (97%)]\tLoss: 0.434073\n",
      "\n",
      "Test set: Average loss: 0.4898, Accuracy: 18412/24482 (75.21%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#criterion = LogisticLoss()\n",
    "#criterion = HingeLoss()\n",
    "criterion = torch.nn.BCELoss(reduction='mean')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # A cada epoca, fem un entrenament del model (es veu un cop cada exemple)\n",
    "    print(\"LEARNING RATE USED: {}\".format(scheduler.get_last_lr()))\n",
    "    train(model, device, train_loader, optimizer, criterion, epoch, log_interval)\n",
    "    test(model, device, test_loader, criterion,show_confusion_matrix=False)\n",
    "    scheduler.step()  # reduim el Learning Rate segons el scheduler StepLR que fa servir gamma\n",
    "\n",
    "if save_model:\n",
    "    torch.save(model.state_dict(), \"mnist.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM,hacer con las 30 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7493260354546197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oriol\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=0.2,random_state =42)\n",
    "lin_clf = svm.LinearSVC()#onevsone\n",
    "lin_clf.fit(X_test_selected, Y_test.values.ravel())\n",
    "y_pred=lin_clf.predict(X_test_selected)\n",
    "# View The Accuracy Of Our Selected Feature Model\n",
    "print(\"Accuracy\",accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oriol\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "model = MLPClassifier()\n",
    "model.fit(X_train_selected, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8563434359937914\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
